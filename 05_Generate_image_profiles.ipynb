{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save images of the depth slices for each reservoir\n",
    "It's important to check each reservoir individually to make sure the images being used as depth-to-surface data points are good quality - eg they are a picture of just the reservoir, not incuding random flooding outside the reservoir, don't have tire tracks through them etc. This notebook will generate images for each reservoir using the same code as query_with_bounding_boxes.ipynb and save each depth of each reservoir as a png file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/env/lib/python3.6/site-packages/geopandas/_compat.py:88: UserWarning: The Shapely GEOS version (3.7.2-CAPI-1.11.0 ) is incompatible with the GEOS version PyGEOS was compiled with (3.9.0-CAPI-1.16.2). Conversions between both will be slow.\n",
      "  shapely_geos_version, geos_capi_version_string\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import xarray as xr\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import csv\n",
    "import rasterio.crs\n",
    "from tqdm.auto import tqdm #this one is a loading bar, it's cool to add loading bars to loops\n",
    "from pandas import DataFrame\n",
    "import geopandas as gpd\n",
    "import matplotlib.gridspec as gs\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import pyplot\n",
    "import datacube\n",
    "\n",
    "import sys\n",
    "sys.path.append('../../Scripts')\n",
    "from dea_spatialtools import xr_rasterize\n",
    "from dea_datahandling import wofs_fuser #this joins wofs data across tiles correctly\n",
    "from datacube.utils import geometry \n",
    "from datacube.utils.geometry import CRS\n",
    "from datacube.utils import masking\n",
    "from datacube.helpers import ga_pq_fuser, write_geotiff\n",
    "#from digitalearthau.utils import wofs_fuser\n",
    "#import DEAPlotting, DEADataHandling\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore', module='datacube')\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e2866f771a7849d38459e6ce6d9c7a4e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/153 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gauge_ID</th>\n",
       "      <th>NAME</th>\n",
       "      <th>staion_nam</th>\n",
       "      <th>ORIG_FID</th>\n",
       "      <th>geometry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TAYLORS</td>\n",
       "      <td>LAKE TAYLOR</td>\n",
       "      <td>Taylors Lake</td>\n",
       "      <td>0</td>\n",
       "      <td>POLYGON ((142.36410 -36.82037, 142.37857 -36.7...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RE604</td>\n",
       "      <td>UPPER STONY CREEK RESERVOIR</td>\n",
       "      <td>Upper Stony</td>\n",
       "      <td>1</td>\n",
       "      <td>POLYGON ((144.19442 -37.81257, 144.21163 -37.8...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sp-o10334</td>\n",
       "      <td>LAKE EILDON</td>\n",
       "      <td>EILDON</td>\n",
       "      <td>2</td>\n",
       "      <td>POLYGON ((145.86701 -36.93337, 146.21666 -37.1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>425022</td>\n",
       "      <td>LAKE MENINDEE</td>\n",
       "      <td>LAKE MENINDEE</td>\n",
       "      <td>3</td>\n",
       "      <td>POLYGON ((142.29594 -32.24831, 142.42359 -32.3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sp-o11534</td>\n",
       "      <td>WARANGA BASIN</td>\n",
       "      <td>WARANGA BASIN</td>\n",
       "      <td>4</td>\n",
       "      <td>POLYGON ((145.02963 -36.55203, 145.11966 -36.4...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>136023A</td>\n",
       "      <td>NED CHURCHWARD WEIR</td>\n",
       "      <td>Ned Churchward HW</td>\n",
       "      <td>148</td>\n",
       "      <td>POLYGON ((151.94635 -25.14140, 152.05044 -25.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>136020A</td>\n",
       "      <td>BEN ANDERSON BARRAGE</td>\n",
       "      <td>Ben Anderson Barrage</td>\n",
       "      <td>149</td>\n",
       "      <td>POLYGON ((152.14677 -24.97170, 152.26926 -24.8...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>136003C</td>\n",
       "      <td>CLAUDE WHARTON WEIR</td>\n",
       "      <td>Claude Wharton HW</td>\n",
       "      <td>150</td>\n",
       "      <td>POLYGON ((151.52403 -25.61861, 151.59165 -25.6...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151</th>\n",
       "      <td>125008A</td>\n",
       "      <td>MARIAN WEIR</td>\n",
       "      <td>Mirani Weir HW</td>\n",
       "      <td>151</td>\n",
       "      <td>POLYGON ((148.82252 -21.15658, 148.92972 -21.1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>125008A</td>\n",
       "      <td>MIRANI WEIR</td>\n",
       "      <td>Mirani Weir HW</td>\n",
       "      <td>152</td>\n",
       "      <td>POLYGON ((148.80675 -21.23068, 148.82208 -21.1...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>153 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      gauge_ID                         NAME            staion_nam  ORIG_FID  \\\n",
       "0      TAYLORS                  LAKE TAYLOR          Taylors Lake         0   \n",
       "1        RE604  UPPER STONY CREEK RESERVOIR           Upper Stony         1   \n",
       "2    sp-o10334                  LAKE EILDON                EILDON         2   \n",
       "3       425022                LAKE MENINDEE         LAKE MENINDEE         3   \n",
       "4    sp-o11534                WARANGA BASIN         WARANGA BASIN         4   \n",
       "..         ...                          ...                   ...       ...   \n",
       "148    136023A          NED CHURCHWARD WEIR     Ned Churchward HW       148   \n",
       "149    136020A         BEN ANDERSON BARRAGE  Ben Anderson Barrage       149   \n",
       "150    136003C          CLAUDE WHARTON WEIR     Claude Wharton HW       150   \n",
       "151    125008A                  MARIAN WEIR        Mirani Weir HW       151   \n",
       "152    125008A                  MIRANI WEIR        Mirani Weir HW       152   \n",
       "\n",
       "                                              geometry  \n",
       "0    POLYGON ((142.36410 -36.82037, 142.37857 -36.7...  \n",
       "1    POLYGON ((144.19442 -37.81257, 144.21163 -37.8...  \n",
       "2    POLYGON ((145.86701 -36.93337, 146.21666 -37.1...  \n",
       "3    POLYGON ((142.29594 -32.24831, 142.42359 -32.3...  \n",
       "4    POLYGON ((145.02963 -36.55203, 145.11966 -36.4...  \n",
       "..                                                 ...  \n",
       "148  POLYGON ((151.94635 -25.14140, 152.05044 -25.0...  \n",
       "149  POLYGON ((152.14677 -24.97170, 152.26926 -24.8...  \n",
       "150  POLYGON ((151.52403 -25.61861, 151.59165 -25.6...  \n",
       "151  POLYGON ((148.82252 -21.15658, 148.92972 -21.1...  \n",
       "152  POLYGON ((148.80675 -21.23068, 148.82208 -21.1...  \n",
       "\n",
       "[153 rows x 5 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gdf = gpd.read_file('00_Lib_bound/00_Lib_bound.shp')\n",
    "\n",
    "query = {'time': ('01-01-1988', '09-12-2020')} \n",
    "         #'crs': 'EPSG:3577'}\n",
    "dc = datacube.Datacube(app='dc-WOfS')\n",
    "\n",
    "results = {} \n",
    "\n",
    "#tqdm is gonna make the bar. tqdm is Arabic abbreviation for 'progress'\n",
    "for index, row in tqdm(gdf.iterrows(), total=len(gdf)):\n",
    "    geom = geometry.Geometry(geom=row.geometry, crs=gdf.crs)\n",
    "    query.update({'geopolygon': geom})\n",
    "    \n",
    "    wofs_albers= dc.load(product = 'wofs_albers', dask_chunks = {}, \n",
    "                         group_by='solar_day', fuse_func = wofs_fuser, **query) #wofs_fuser is important, it fixes thing on the edge of tiles\n",
    "    \n",
    "    poly_mask = xr_rasterize(gdf.iloc[[index]], wofs_albers)\n",
    "    wofs_albers = wofs_albers.where(poly_mask, other=wofs_albers.water.nodata) #put other argument or all the data turns into 0\n",
    "    \n",
    "    results.update({str(row['gauge_ID']): wofs_albers}) #The handle for dictionary objects is the gauge ID\n",
    "gdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make a list of the file names so we can call them with pandas\n",
    "file_list = []\n",
    "\n",
    "directory = '00_Library'\n",
    "for filename in os.listdir(directory):\n",
    "    if filename.endswith(\".csv\"):\n",
    "        file_list.append(os.path.join(directory, filename))\n",
    "\n",
    "#Read the gauge files twice, once to get ID and second to get the data. Append them together in a dictionary\n",
    "#May as well make a list of IDs here because we will probably use it later\n",
    "data_dict = {}        \n",
    "ID_list = []\n",
    "#let's use tqdm again to make a progress bar. The bar is so cool I love this module\n",
    "#I'm gonna use tqdm on literally all of my loops now\n",
    "for i in tqdm(file_list, total=len(file_list)):\n",
    "    df = pd.read_csv(i, nrows=1, escapechar='#')\n",
    "    column = df.iloc[:,[1]] #This is the column with the ID in it\n",
    "    ID = list(column)\n",
    "    ID = ID[0]\n",
    "    ID = df.at[0, ID]\n",
    "    ID_list.append(str(ID))\n",
    "    \n",
    "    data = pd.read_csv(i, error_bad_lines = False, skiprows=9, escapechar='#',\n",
    "                         parse_dates=['Timestamp'], \n",
    "                         index_col=('Timestamp'),\n",
    "                        date_parser=lambda x: pd.to_datetime(x.rsplit('+', 1)[0]))\n",
    "    data = data.drop(columns=['Quality Code', 'Interpolation Type'])\n",
    "    data_dict.update({str(ID): data}) #Now we have the gauge data, again with the gauge ID as the handle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ID_list_cut = ID_list[-9:]\n",
    "ID_list_cut "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_prod(ID_caller, gauge_data, wofs_albers, make_plots = False) -> 'depth slices': \n",
    "    \"\"\"\n",
    "    This function takes the gauge data and the wofs data,\n",
    "    cloud masks the images and counts the pixels in each depth slice.\n",
    "    It saves png images into the 'images/' folder.\n",
    "    \n",
    "    \"\"\"\n",
    "    #Get the depth range and intervals\n",
    "    gauge_data = gauge_data.dropna()\n",
    "    depth_integers = gauge_data.astype(np.int64)\n",
    "    max_depth = depth_integers.Value.max()\n",
    "    min_depth = depth_integers.Value.min()\n",
    "    integer_array = depth_integers.Value.unique()\n",
    "    integer_list = integer_array.tolist()\n",
    "    \n",
    "    gauge_data_xr = gauge_data.to_xarray() #convert gauge data to xarray\n",
    "    merged_data = gauge_data_xr.interp(Timestamp=wofs_albers.time) #use xarrays .interp() function to merge\n",
    "\n",
    "    images = []\n",
    "\n",
    "    for i in tqdm(integer_list, leave = False):\n",
    "        if len(integer_list) > 25: #If the depth range is more than 25 1m intervals, take every 2m instead of 1m\n",
    "            specified_level = merged_data.where((merged_data.Value > i) & \n",
    "                                (merged_data.Value < i+2), drop=True)\n",
    "        else:\n",
    "            specified_level = merged_data.where((merged_data.Value > i) & \n",
    "                                (merged_data.Value < i+1), drop=True)\n",
    "\n",
    "\n",
    "        date_list = specified_level.time.values#[:150] #caps images at x per slice (way faster)\n",
    "        n_images_used = int(len(date_list))\n",
    "        specified_passes = wofs_albers.sel(time=date_list).compute() #This .compute() Xarray function loads actual images\n",
    "        #cloudmask (Claire Krause wrote this for me)\n",
    "        #print(specified_passes.water)\n",
    "        cc = masking.make_mask(specified_passes.water, cloud=True)\n",
    "        ncloud_pixels = cc.sum(dim=['x', 'y'])\n",
    "        # Calculate the total number of pixels per timestep\n",
    "        npixels_per_slice = (specified_passes.water.shape[1] * \n",
    "                             specified_passes.water.shape[2])\n",
    "        cloud_pixels_fraction = (ncloud_pixels / npixels_per_slice)\n",
    "        clear_specified_passes = specified_passes.water.isel(\n",
    "            time=cloud_pixels_fraction < 0.2) #has to be under 20% cloudy to pass\n",
    "        wet = masking.make_mask(clear_specified_passes, wet=True).sum(dim='time')\n",
    "        dry = masking.make_mask(clear_specified_passes, dry=True).sum(dim='time')\n",
    "        clear = wet + dry\n",
    "        frequency = wet / clear\n",
    "        frequency = frequency.fillna(0)  \n",
    "\n",
    "        #Get area from the satellite data\n",
    "        #get the frequency array\n",
    "        frequency_array = frequency.values\n",
    "        n_images_cm = len(frequency_array)\n",
    "        #Turn any pixel in the frequency array with a value greater than 0.2 into a pixel of value 1\n",
    "        #if the pixel value is 0.2 or lower it gets value 0\n",
    "        is_water = np.where((frequency_array > 0.2),1,0) #has to be water in more than 20% of images to count\n",
    "        #give the 'frequency' xarray back its new values of zero and one\n",
    "        frequency.values = is_water\n",
    "        #sum up the pixels\n",
    "        number_water_pixels = frequency.sum(dim=['x', 'y'])\n",
    "        #get the number\n",
    "        number_water_pixels = number_water_pixels.values.tolist()\n",
    "        #multiply by pixel size to get area in m2\n",
    "        area_m2 = number_water_pixels*(25*25)\n",
    "        \n",
    "        \n",
    "        frequency.plot(figsize = (7,5))\n",
    "        name = ID_caller, i\n",
    "        images = plt.savefig('images/'+str(name)+'.png')\n",
    "\n",
    "        #Plotting the image\n",
    "        if make_plots:\n",
    "            frequency.plot(figsize = (7,5))\n",
    "    del wofs_albers\n",
    "    del specified_passes\n",
    "    del cc\n",
    "    del clear_specified_passes\n",
    "    del wet\n",
    "    del dry\n",
    "    del clear\n",
    "    del frequency\n",
    "    #delete the images when you finish each reservoir (otherwise the memory will run out and the kernel will break)\n",
    "    return images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "array_list = []\n",
    "\n",
    "\n",
    "def listsplit(N, K=1):\n",
    "    length = len(N)\n",
    "    return [N[i*length/K: (i+1)*length/K] for i in range(K)]\n",
    "\n",
    "\n",
    "for ID in tqdm(ID_list_cut, total=len(ID_list)):\n",
    "    print(\"Working on gauge \", ID)\n",
    "    if (ID in data_dict.keys()) and (ID in results.keys()):\n",
    "        data = image_prod(ID, data_dict[ID], results[ID], make_plots = False)\n",
    "        array_list.append(data)\n",
    "        \n",
    "        del data\n",
    "    else:\n",
    "        print('we didnt find', ID)     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
